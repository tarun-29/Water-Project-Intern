{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599334621514",
   "display_name": "Python 3.7.7 64-bit ('CVcourse': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "plt.style.use(\"seaborn-colorblind\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1991, 3)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Temp D.O. (mg/l)   PH\n0  30.6         6.7  7.5\n1  29.8         5.7  7.2\n2  29.5         6.3  6.9\n3  29.7         5.8  6.9\n4  29.5         5.8  7.3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Temp</th>\n      <th>D.O. (mg/l)</th>\n      <th>PH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.6</td>\n      <td>6.7</td>\n      <td>7.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29.8</td>\n      <td>5.7</td>\n      <td>7.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29.5</td>\n      <td>6.3</td>\n      <td>6.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29.7</td>\n      <td>5.8</td>\n      <td>6.9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.5</td>\n      <td>5.8</td>\n      <td>7.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "used_features = [\"Temp\", \"PH\",\"D.O. (mg/l)\"]\n",
    "water = pd.read_csv('waterdata.csv', usecols = used_features, encoding= 'unicode_escape')\n",
    "# m = pd.read_csv('waterdata.csv', encoding= 'unicode_escape')\n",
    "# target[\"D.O. (mg/l)\"] = m[\"D.O. (mg/l)\"]\n",
    "print(water.shape)\n",
    "water.head()\n",
    "# target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "water[\"Temp\"] = pd.to_numeric(water['Temp'], errors='coerce')\n",
    "water[\"Temp\"] = water[\"Temp\"].replace(np.nan, 0)\n",
    "water[\"PH\"] = pd.to_numeric(water['PH'], errors='coerce')\n",
    "water[\"PH\"] = water[\"PH\"].replace(np.nan, 0)\n",
    "water[\"D.O. (mg/l)\"] = pd.to_numeric(water[\"D.O. (mg/l)\"], errors='coerce')\n",
    "water[\"D.O. (mg/l)\"] = water[\"D.O. (mg/l)\"].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "water=water.mask(water[\"Temp\"]==0).fillna(water[\"Temp\"].mean())\n",
    "water=water.mask(water[\"PH\"]==0).fillna(water[\"PH\"].mean())\n",
    "water=water.mask(water[\"D.O. (mg/l)\"]==0).fillna(water[\"D.O. (mg/l)\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           Temp  D.O. (mg/l)          PH\n0     30.600000     6.700000    7.500000\n1     29.800000     5.700000    7.200000\n2     29.500000     6.300000    6.900000\n3     29.700000     5.800000    6.900000\n4     29.500000     5.800000    7.300000\n...         ...          ...         ...\n1986  24.998713    24.998713   24.998713\n1987  29.000000     7.500000  585.000000\n1988  28.000000     7.600000   98.000000\n1989  28.000000     7.700000   91.000000\n1990  29.000000     7.600000  110.000000\n\n[1991 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Temp</th>\n      <th>D.O. (mg/l)</th>\n      <th>PH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.600000</td>\n      <td>6.700000</td>\n      <td>7.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29.800000</td>\n      <td>5.700000</td>\n      <td>7.200000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29.500000</td>\n      <td>6.300000</td>\n      <td>6.900000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29.700000</td>\n      <td>5.800000</td>\n      <td>6.900000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.500000</td>\n      <td>5.800000</td>\n      <td>7.300000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>24.998713</td>\n      <td>24.998713</td>\n      <td>24.998713</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <td>29.000000</td>\n      <td>7.500000</td>\n      <td>585.000000</td>\n    </tr>\n    <tr>\n      <th>1988</th>\n      <td>28.000000</td>\n      <td>7.600000</td>\n      <td>98.000000</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>28.000000</td>\n      <td>7.700000</td>\n      <td>91.000000</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>29.000000</td>\n      <td>7.600000</td>\n      <td>110.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1991 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = water[\"D.O. (mg/l)\"]\n",
    "features = water.drop('D.O. (mg/l)',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           Temp          PH\n0     30.600000    7.500000\n1     29.800000    7.200000\n2     29.500000    6.900000\n3     29.700000    6.900000\n4     29.500000    7.300000\n...         ...         ...\n1986  24.998713   24.998713\n1987  29.000000  585.000000\n1988  28.000000   98.000000\n1989  28.000000   91.000000\n1990  29.000000  110.000000\n\n[1991 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Temp</th>\n      <th>PH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30.600000</td>\n      <td>7.500000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29.800000</td>\n      <td>7.200000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>29.500000</td>\n      <td>6.900000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29.700000</td>\n      <td>6.900000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>29.500000</td>\n      <td>7.300000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>24.998713</td>\n      <td>24.998713</td>\n    </tr>\n    <tr>\n      <th>1987</th>\n      <td>29.000000</td>\n      <td>585.000000</td>\n    </tr>\n    <tr>\n      <th>1988</th>\n      <td>28.000000</td>\n      <td>98.000000</td>\n    </tr>\n    <tr>\n      <th>1989</th>\n      <td>28.000000</td>\n      <td>91.000000</td>\n    </tr>\n    <tr>\n      <th>1990</th>\n      <td>29.000000</td>\n      <td>110.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1991 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0        6.700000\n1        5.700000\n2        6.300000\n3        5.800000\n4        5.800000\n          ...    \n1986    24.998713\n1987     7.500000\n1988     7.600000\n1989     7.700000\n1990     7.600000\nName: D.O. (mg/l), Length: 1991, dtype: float64"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     water, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Temp    PH\n887   28.8  7.50\n1670  16.0  7.00\n414   28.0  8.20\n1080  26.4  7.70\n1102  28.1  6.90\n...    ...   ...\n1857  18.0  3.05\n522   28.0  6.60\n513   30.0  6.80\n81    26.0  7.50\n720   28.0  7.50\n\n[658 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Temp</th>\n      <th>PH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>887</th>\n      <td>28.8</td>\n      <td>7.50</td>\n    </tr>\n    <tr>\n      <th>1670</th>\n      <td>16.0</td>\n      <td>7.00</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>28.0</td>\n      <td>8.20</td>\n    </tr>\n    <tr>\n      <th>1080</th>\n      <td>26.4</td>\n      <td>7.70</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>28.1</td>\n      <td>6.90</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1857</th>\n      <td>18.0</td>\n      <td>3.05</td>\n    </tr>\n    <tr>\n      <th>522</th>\n      <td>28.0</td>\n      <td>6.60</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>30.0</td>\n      <td>6.80</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>26.0</td>\n      <td>7.50</td>\n    </tr>\n    <tr>\n      <th>720</th>\n      <td>28.0</td>\n      <td>7.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>658 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# numeric_columns = [\"Temp\", \"PH\",\"D.O. (mg/l)\"]\n",
    "numeric_columns = [\"Temp\", \"PH\"]\n",
    "X_train.drop('D.O. (mg/l)',axis=1, inplace=True)\n",
    "X_test.drop('D.O. (mg/l)',axis=1, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "NumericColumn(key='Temp', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)\n"
    }
   ],
   "source": [
    "numeric_features = [tf.feature_column.numeric_column(key = column) for column in numeric_columns]\n",
    "print(numeric_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_features = numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=32, shuffle=True, num_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_test, y=y_test, batch_size=32, shuffle=False, num_epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_model_dir': 'linear_regressor', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\ngraph_options {\n  rewrite_options {\n    meta_optimizer_iterations: ONE\n  }\n}\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
    }
   ],
   "source": [
    "linear_regressor = tf.estimator.LinearRegressor(feature_columns=linear_features,\n",
    "                                                model_dir = \"linear_regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Create CheckpointSaverHook.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from linear_regressor/model.ckpt-4000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4000...\nINFO:tensorflow:Saving checkpoints for 4000 into linear_regressor/model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4000...\nINFO:tensorflow:loss = 113.65925, step = 4000\nINFO:tensorflow:global_step/sec: 641.712\nINFO:tensorflow:loss = 2.7180662, step = 4100 (0.157 sec)\nINFO:tensorflow:global_step/sec: 796.954\nINFO:tensorflow:loss = 14.731831, step = 4200 (0.128 sec)\nINFO:tensorflow:global_step/sec: 754.153\nINFO:tensorflow:loss = 23.785484, step = 4300 (0.132 sec)\nINFO:tensorflow:global_step/sec: 793.62\nINFO:tensorflow:loss = 34.16308, step = 4400 (0.139 sec)\nINFO:tensorflow:global_step/sec: 731.171\nINFO:tensorflow:loss = 32.181858, step = 4500 (0.123 sec)\nINFO:tensorflow:global_step/sec: 727.674\nINFO:tensorflow:loss = 44.6157, step = 4600 (0.137 sec)\nWARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4671 vs previous value: 4671. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\nINFO:tensorflow:global_step/sec: 383.832\nINFO:tensorflow:loss = 14.161814, step = 4700 (0.265 sec)\nINFO:tensorflow:global_step/sec: 648.437\nINFO:tensorflow:loss = 32.99935, step = 4800 (0.150 sec)\nINFO:tensorflow:global_step/sec: 758.646\nINFO:tensorflow:loss = 3.3704042, step = 4900 (0.136 sec)\nINFO:tensorflow:global_step/sec: 437.838\nINFO:tensorflow:loss = 16.797138, step = 5000 (0.225 sec)\nINFO:tensorflow:global_step/sec: 491.956\nINFO:tensorflow:loss = 54.546696, step = 5100 (0.203 sec)\nINFO:tensorflow:global_step/sec: 518.396\nINFO:tensorflow:loss = 23.679287, step = 5200 (0.192 sec)\nINFO:tensorflow:global_step/sec: 407.523\nINFO:tensorflow:loss = 24.55113, step = 5300 (0.250 sec)\nINFO:tensorflow:global_step/sec: 582.923\nINFO:tensorflow:loss = 42.81515, step = 5400 (0.170 sec)\nINFO:tensorflow:global_step/sec: 586.899\nINFO:tensorflow:loss = 2.1230283, step = 5500 (0.172 sec)\nINFO:tensorflow:global_step/sec: 836.192\nINFO:tensorflow:loss = 12.373795, step = 5600 (0.117 sec)\nINFO:tensorflow:global_step/sec: 675.279\nINFO:tensorflow:loss = 23.51104, step = 5700 (0.152 sec)\nWARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 5772 vs previous value: 5772. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\nINFO:tensorflow:global_step/sec: 468.836\nINFO:tensorflow:loss = 11.880002, step = 5800 (0.210 sec)\nINFO:tensorflow:global_step/sec: 522.417\nINFO:tensorflow:loss = 23.695572, step = 5900 (0.190 sec)\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6000...\nINFO:tensorflow:Saving checkpoints for 6000 into linear_regressor/model.ckpt.\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6000...\nINFO:tensorflow:Loss for final step: 13.149958.\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7ff5df9cc510>"
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "linear_regressor.train(input_fn = training_input_fn,steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Starting evaluation at 2020-09-06T15:52:22Z\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from linear_regressor/model.ckpt-6000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nINFO:tensorflow:Inference Time : 0.26107s\nINFO:tensorflow:Finished evaluation at 2020-09-06-15:52:22\nINFO:tensorflow:Saving dict for global step 6000: average_loss = 15.832931, global_step = 6000, label/mean = 7.1882124, loss = 16.302292, prediction/mean = 7.082533\nINFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: linear_regressor/model.ckpt-6000\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'average_loss': 15.832931,\n 'label/mean': 7.1882124,\n 'loss': 16.302292,\n 'prediction/mean': 7.082533,\n 'global_step': 6000}"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "linear_regressor.evaluate(input_fn = eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nWARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from linear_regressor/model.ckpt-6000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n"
    }
   ],
   "source": [
    "pred = list(linear_regressor.predict(input_fn = eval_input_fn))\n",
    "pred = [p['predictions'][0] for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[7.7698073, 4.650268, 7.57485, 7.1848993, 7.5991964, 6.28316, 7.8185596, 7.3311253, 4.650266, 7.5748096, 5.79573, 5.771349, 7.836882, 7.574816, 6.8437138, 5.576372, 7.5992002, 7.2823977, 7.5748367, 6.5999913, 7.3311195, 5.871384, 8.062252, 6.112559, 7.3311176, 6.112551, 7.745438, 8.06226, 7.4529953, 5.698229, 7.8185368, 7.721074, 7.0874004, 7.609673, 7.5748253, 5.381424, 7.452965, 7.3311195, 7.5748196, 7.818533, 7.0630426, 6.11247, 7.3311253, 5.1376963, 6.5756083, 8.062254, 7.745442, 7.8429155, 6.868068, 8.257228, 8.086633, 7.404247, 7.8185444, 7.355491, 7.5504537, 6.5999665, 7.33111, 7.4529624, 6.8436913, 7.745438, 7.5748143, 6.868074, 7.5017056, 7.5748215, 2.5098643, 8.013524, 7.5748386, 7.842925, 7.0873857, 3.4317036, 7.3554893, 6.356261, 7.940405, 6.8437138, 7.3067408, 8.110996, 7.404226, 7.5748386, 6.3562665, 7.3311214, 5.625142, 5.0402074, 7.69668, 5.1377, 7.8185463, 7.818533, 6.8437138, 5.8688455, 7.331108, 7.6479263, 7.0873985, 8.281595, 7.8267574, 7.332115, 7.5188904, 7.8185463, 7.087408, 6.3075237, 6.8437138, 7.087406, 6.8437138, 5.332665, 7.452986, 7.08741, 7.3311157, 6.356276, 6.3562646, 7.81855, 5.600755, 7.745423, 7.6966786, 6.8437138, 7.6723123, 7.8185463, 7.3392363, 8.062258, 7.087412, 8.062275, 7.5748177, 6.8437138, 7.5748615, 5.4788947, 6.8437138, 7.2701807, 6.0638046, 7.6479545, 7.62357, 7.282392, 8.037891, 7.574829, 5.186439, 7.3311176, 5.3814135, 7.2092543, 5.4545217, 6.1125607, 5.8688455, 7.2092705, 7.0142813, 6.356261, 7.882329, 7.331101, 8.06225, 7.5748324, 7.8185368, 7.3311176, 7.5748253, 8.793402, 7.0873857, 7.8185463, 7.428595, 7.0873947, 6.9168105, 7.148321, 7.574816, 6.8436894, 7.160505, 6.697465, 7.331114, 7.5260806, 6.746189, 6.185663, 5.3082957, 7.745417, 6.819318, 7.3311176, 7.087408, 5.625121, 8.062275, 8.062262, 5.871044, 6.1125493, 5.6982365, 8.135362, 7.8185463, 7.0873876, 7.5748444, 7.331103, 5.137698, 7.7373934, 6.4537477, 8.793406, 8.309196, 6.7705755, 7.5260825, 7.5748444, 7.1361585, 6.112553, 7.0873947, 7.672318, 6.5999894, 7.0874166, 7.3311253, 8.062269, 7.2336307, 7.5748234, 7.623568, 6.8437138, 6.063731, 7.209276, 7.404239, 5.625123, 7.8185406, 7.5991983, 8.086627, 8.086625, 6.3562684, 7.087412, 8.695904, 7.5748425, 6.8437047, 7.818533, 7.1605163, 7.574846, 6.8437138, 7.5748425, 6.5268774, 6.380642, 7.1605163, 6.234402, 7.501742, 6.843699, 7.0386615, 5.8688493, 7.33111, 7.575866, 5.357038, 7.087406, 7.8185463, 8.062271, 5.625123, 7.526066, 8.184116, 7.574827, 6.5999837, 8.062262, 6.185667, 7.818531, 7.5748215, 7.891652, 7.379853, 7.0874023, 7.818522, 6.843701, 7.574829, 7.282369, 7.501721, 7.0874023, 7.087412, 7.339293, 7.47734, 5.357036, 6.8436933, 6.8437138, 6.8437138, 8.062254, 6.3562913, 7.5748463, 8.0135145, 8.06225, 7.5260997, 7.0386767, 7.087406, 7.5991964, 7.2336307, 7.8185387, 5.210812, 2.5098643, 8.013507, 5.8688397, 6.599978, 6.6018634, 6.599982, 7.087412, 7.2580132, 6.3562665, 5.186437, 8.842436, 7.513898, 7.3311195, 8.062252, 5.6251307, 7.59921, 8.57418, 6.843699, 8.013524, 6.965534, 4.893983, 8.062267, 7.526077, 7.5748234, 7.8185387, 7.0874214, 7.3311195, 7.7576137, 7.8185444, 7.9891534, 7.331127, 7.0386653, 7.8196363, 6.8436933, 7.331108, 7.355491, 7.818535, 6.5432053, 7.331112, 7.9647856, 8.062279, 6.112557, 8.062265, 7.5748367, 7.574831, 5.1377115, 7.574835, 6.843697, 7.574831, 7.087412, 7.4042354, 5.868838, 6.356246, 7.7454343, 7.6966896, 6.112563, 8.072321, 6.599982, 7.818552, 7.5748177, 6.5999837, 7.574831, 7.3311176, 7.574852, 7.0874157, 6.8437138, 5.868838, 5.6251287, 7.574833, 7.818552, 7.3311214, 7.819542, 7.331112, 5.137704, 8.062273, 7.5748234, 7.1219296, 7.5963798, 5.8688416, 7.818554, 5.381419, 5.0645785, 7.088364, 7.0873857, 7.5991964, 8.305986, 7.2580094, 7.0873857, 7.818548, 7.3311234, 7.087414, 7.769815, 7.33111, 6.8680778, 8.062256, 6.234402, 7.3318505, 6.721844, 5.6251154, 8.03788, 7.574835, 6.8436837, 7.0142965, 6.7949634, 8.3059635, 6.8437138, 5.218864, 6.258766, 7.331129, 7.6235814, 6.8437138, 7.574831, 5.3814096, 8.305969, 6.112555, 6.1125493, 8.062262, 5.1376925, 7.8185463, 5.8688416, 7.8185425, 2.5098643, 7.818554, 5.3814116, 7.574816, 7.33111, 5.1377015, 7.696686, 8.0622635, 8.062275, 7.0874157, 6.5024905, 7.5748463, 7.331103, 7.576131, 7.3032403, 7.1605277, 7.3311176, 2.5098643, 8.062277, 7.574848, 7.3311043, 5.113321, 7.0874043, 6.8924284, 7.087393, 7.8185673, 7.477348, 6.9655533, 7.258017, 7.752555, 7.5748253, 7.087408, 7.5748196, 6.4293785, 6.6730933, 6.8437138, 6.6974688, 7.282371, 7.5748196, 6.599963, 8.062267, 7.0386653, 5.8688474, 5.966331, 6.3582444, 7.5748405, 6.8436956, 7.355491, 7.0874157, 6.673095, 6.8437138, 7.574829, 6.8436913, 7.5748262, 7.574831, 7.087391, 4.650268, 7.3311176, 7.160524, 6.4781327, 7.9403954, 6.5999875, 5.868836, 5.8688493, 6.794948, 7.574831, 7.5748425, 5.1133265, 8.086637, 7.62357, 6.1856804, 7.331139, 6.4781213, 7.6235604, 5.9907002, 7.769798, 7.233646, 5.357038, 6.453746, 5.3814116, 7.331127, 7.977618, 7.574831, 7.574829, 6.8436904, 7.57485, 7.769798, 8.549685, 6.8437138, 7.5748215, 6.8437138, 7.5748405, 5.1376944, 7.331129, 7.8185277, 7.745438, 7.5748463, 7.4042277, 7.087406, 7.331114, 7.5748234, 6.8437138, 7.331108, 7.0062623, 7.477363, 7.5748177, 7.184882, 7.0630465, 6.84368, 7.404247, 8.549686, 7.8185577, 7.574831, 6.4293785, 8.086633, 6.3562684, 7.0142794, 7.6235814, 8.062252, 7.574833, 7.4042525, 7.3311243, 7.8185387, 5.2351813, 3.1879885, 7.623585, 7.9647646, 7.3311253, 7.5748253, 7.0873857, 7.136147, 5.8688397, 7.8185616, 6.5188327, 7.5748067, 7.5748215, 7.452978, 7.331129, 6.8437138, 7.282377, 6.6730876, 7.8185406, 7.5748196, 7.1361356, 6.8437138, 7.8185406, 8.305986, 5.332669, 6.868068, 6.599984, 7.769783, 7.3554816, 7.5748215, 7.575526, 6.063816, 7.818552, 6.843699, 7.745444, 6.600003, 7.3798623, 7.9404087, 7.0873947, 7.2336364, 7.4529953, 7.331114, 7.5748105, 7.452963, 7.0874076, 6.526862, 4.4091043, 7.331114, 6.8436913, 7.818556, 7.6235604, 7.5748196, 6.8436856, 7.5748196, 8.0378895, 7.8185406, 6.112553, 7.379853, 6.1125607, 5.1376944, 7.5748215, 8.305983, 7.818532, 7.5748405, 7.821242, 7.8185425, 7.8250575, 7.2092547, 7.8672986, 7.3311043, 7.28239, 6.599982, 7.331127, 7.6479487, 5.332667, 7.5139127, 6.599999, 6.356276, 7.891654, 7.087406, 6.5999894, 5.1376944, 6.3562684, 6.3562703, 7.769787, 7.087393, 6.3562703, 8.06226, 5.8688416, 7.4042487, 8.793407, 7.8185577, 8.305988, 7.9647627, 7.0873857, 7.574848, 6.8436913, 7.6723027, 3.6754205, 7.574831, 4.406479, 7.0874214, 8.793411, 7.3311195, 7.0874004, 7.2579923, 6.3562694, 6.35627, 7.331112, 7.6723275, 7.5260715, 8.062271, 7.331114, 6.283149, 7.5748215, 7.745419, 6.8437138, 7.501721, 7.0386653, 5.625127, 7.5748444, 5.381408, 6.8437138, 7.16052, 6.843695, 6.8437066, 7.5748405, 7.574827, 7.5748253, 6.8437138, 8.0622635, 7.0142946, 7.452984, 8.062281, 7.8916483, 6.356272, 7.8185277, 6.8437138, 5.2108235, 6.599975, 7.5991964, 7.331103, 5.13762, 7.5748196, 8.06225, 7.08741, 7.5748367]\n"
    }
   ],
   "source": [
    "prices = (pred)\n",
    "print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      Temp    PH\n887   28.8  7.50\n1670  16.0  7.00\n414   28.0  8.20\n1080  26.4  7.70\n1102  28.1  6.90\n...    ...   ...\n1857  18.0  3.05\n522   28.0  6.60\n513   30.0  6.80\n81    26.0  7.50\n720   28.0  7.50\n\n[658 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Temp</th>\n      <th>PH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>887</th>\n      <td>28.8</td>\n      <td>7.50</td>\n    </tr>\n    <tr>\n      <th>1670</th>\n      <td>16.0</td>\n      <td>7.00</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>28.0</td>\n      <td>8.20</td>\n    </tr>\n    <tr>\n      <th>1080</th>\n      <td>26.4</td>\n      <td>7.70</td>\n    </tr>\n    <tr>\n      <th>1102</th>\n      <td>28.1</td>\n      <td>6.90</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1857</th>\n      <td>18.0</td>\n      <td>3.05</td>\n    </tr>\n    <tr>\n      <th>522</th>\n      <td>28.0</td>\n      <td>6.60</td>\n    </tr>\n    <tr>\n      <th>513</th>\n      <td>30.0</td>\n      <td>6.80</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>26.0</td>\n      <td>7.50</td>\n    </tr>\n    <tr>\n      <th>720</th>\n      <td>28.0</td>\n      <td>7.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>658 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "887     6.5\n1670    8.0\n414     8.0\n1080    6.8\n1102    6.7\n       ... \n1857    6.4\n522     6.8\n513     6.1\n81      6.7\n720     8.9\nName: D.O. (mg/l), Length: 658, dtype: float64"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_x = {\n",
    "    'Temp': [30.1],\n",
    "    'PH': [7.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    \"\"\"An input function for prediction.\"\"\"\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = linear_regressor.predict(\n",
    "    input_fn=lambda: input_fn(predict_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<generator object Estimator.predict at 0x7ff5e224fbd0>"
     },
     "metadata": {},
     "execution_count": 160
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from linear_regressor/model.ckpt-6000\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\n"
    }
   ],
   "source": [
    "pred = [p['predictions'][0] for p in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[8.086635]"
     },
     "metadata": {},
     "execution_count": 162
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}